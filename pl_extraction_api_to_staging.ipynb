{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pl_extraction_api_to_staging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWBmn3Q52ZAeHLlOG0XMCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrian-ja-projects/train-prediction-project/blob/fea_data_analisys/pl_extraction_api_to_staging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLOCbChSh4KN"
      },
      "source": [
        "import datetime\n",
        "import requests\n",
        "import json\n",
        "from os.path import exists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IncPJMirPfsA"
      },
      "source": [
        "## Extract from API to Staging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs6Ufp5ukuN9"
      },
      "source": [
        "def _get_date_list(num_days: int, start_year: int, start_month: int, start_day: int)-> list:\n",
        "  \"\"\"\n",
        "  method to get the list of json files to download based on the date\n",
        "  \"\"\"\n",
        "  base = datetime.datetime(start_year, start_month, start_day)\n",
        "  return  [(base + datetime.timedelta(days=x)).strftime(\"%Y-%m-%d\") for x in range(num_days)]\n",
        "\n",
        "def _get_train_metadata_json(departure_date: str, train_number: str) -> None:\n",
        "  \"\"\"\n",
        "  read data from the api of only one departure date at the time\n",
        "  \"\"\"\n",
        "  url = f\"https://rata.digitraffic.fi/api/v1/trains/{departure_date}/{train_number}?include_deleted=false&version=0\"\n",
        "  response = requests.get(url).json()\n",
        "  return response\n",
        "\n",
        "def _check_object_exists(file_path: str)-> bool:\n",
        "  \"\"\"\n",
        "  method to check if object exists\n",
        "  \"\"\"\n",
        "  return exists(file_path)\n",
        "\n",
        "def _overwrite_file(file_path: str)-> None:\n",
        "  \"\"\"\n",
        "  delete a file to overwrite\n",
        "  \"\"\"\n",
        "  delete_file = !rm \"$file_path\"\n",
        "  delete_file\n",
        "  create_file = !touch \"$file_path\"\n",
        "  create_file\n",
        "\n",
        "def _create_file(staging_path: str, file_path: str)-> None:\n",
        "  \"\"\"\n",
        "  create a empty file to write into\n",
        "  \"\"\"\n",
        "  create_dir = !mkdir -p \"$staging_path\"\n",
        "  create_dir\n",
        "  create_empty_file = !touch \"$file_path\"\n",
        "  create_empty_file\n",
        "\n",
        "def write_json_to_staging(departure_date: str, file_format: str, train_number: str, overwrite: bool)-> None:\n",
        "  \"\"\"\n",
        "  call the api and storage the json file into the staging folder with the following path convnetion:\n",
        "  stating/table_name/departure_month/departure_date/table_name.(format)\n",
        "  \"\"\"\n",
        "  staging_path = f\"/content/staging/digitraffic/stg_{train_number}_schedule/{departure_date[0:7]}/{departure_date}/\"\n",
        "  file_name = f\"stg_{train_number}_schedule.{file_format}\"\n",
        "  file_path = staging_path+file_name\n",
        "  if _check_object_exists(file_path):\n",
        "    if overwrite:\n",
        "      _overwrite_file(file_path)\n",
        "  else:\n",
        "     _create_file(staging_path, file_path)\n",
        "  with open(file_path, 'w') as json_file:\n",
        "    data = _get_train_metadata_json(departure_date, train_number)\n",
        "    json.dump(data, json_file)\n",
        "    json_file.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #TO-DO-> get this variables from a scheduled pipeline metadata\n",
        "  num_days = 100\n",
        "  start_year = 2020\n",
        "  start_month = 1\n",
        "  start_day = 1\n",
        "  print(\"INFO: Creating list for extraction loop...\")\n",
        "  dates_of_extraction = _get_date_list(num_days, start_year, start_month, start_day)\n",
        "  print(f\"INFO: Extraction dates are between {min(dates_of_extraction)} and {max(dates_of_extraction)}\")\n",
        "  print(\"INFO: Starting extraction...\")\n",
        "  \n",
        "  for d in dates_of_extraction:\n",
        "    #Make an API call per date and write into staging\n",
        "    #TO-DO-> get this variables from a scheduled pipeline metadata\n",
        "    departure_date = d\n",
        "    file_format = \"json\"\n",
        "    train_number = \"27\"\n",
        "    overwrite = True\n",
        "    write_json_to_staging(departure_date, file_format, train_number, overwrite)\n",
        "  print(f\"INFO: Extraction completed a total of {len(dates_of_extraction)} file were successfully extracted into the staging area\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}